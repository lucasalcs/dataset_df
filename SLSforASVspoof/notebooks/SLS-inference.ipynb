{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLSforASVspoof Deepfake Detection Notebook\n",
    "\n",
    "This notebook demonstrates how to use the SLS (Supervised Label Smoothing) model for detecting deepfake audio samples, based on the original implementation from the [SLSforASVspoof-2021-DF](https://github.com/QiShanZhang/SLSforASVspoof-2021-DF) repository.\n",
    "\n",
    "**Steps:**\n",
    "1. Import dependencies and define utility functions\n",
    "2. Load audio files from a directory\n",
    "3. Define preprocessing functions for audio data\n",
    "4. Load the pretrained SLS model\n",
    "5. Run batch inference on audio files\n",
    "6. Visualize detection scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sys\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "\n",
    "# Critical: Add the repository root to path so we can import modules correctly\n",
    "# Make sure this points to the directory containing the model.py file\n",
    "sys.path.append('..')  # Add parent directory to path\n",
    "\n",
    "# Import the actual model from the repository\n",
    "from model import Model\n",
    "\n",
    "def get_audio_files_recursive(folder_path, formats=('wav', 'flac'), exclude_prefix=('.', '__')):\n",
    "    \"\"\"\n",
    "    Recursively find audio files in a directory with specified extensions.\n",
    "    \n",
    "    Args:\n",
    "        folder_path (str): Root directory to search.\n",
    "        formats (tuple): File extensions to include (lowercase).\n",
    "        exclude_prefix (tuple): Skip directories starting with these prefixes.\n",
    "    \n",
    "    Returns:\n",
    "        list: Full paths to audio files.\n",
    "    \"\"\"\n",
    "    valid_files = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        # Skip hidden or special directories\n",
    "        dirs[:] = [d for d in dirs if not d.startswith(exclude_prefix)]\n",
    "        for file in files:\n",
    "            ext = os.path.splitext(file)[1][1:].lower()  # Extension without the dot\n",
    "            if ext in formats:\n",
    "                full_path = os.path.join(root, file)\n",
    "                valid_files.append(full_path)\n",
    "    return valid_files\n",
    "\n",
    "# Set path to your audio files directory\n",
    "input_folder = '/data/audio_files'  # Update this to your actual audio directory\n",
    "file_paths = get_audio_files_recursive(input_folder, formats=('wav', 'flac'))\n",
    "print(f\"Found {len(file_paths)} audio files ({', '.join(set([os.path.splitext(f)[1] for f in file_paths]))} formats)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple argparse Namespace to mimic command-line arguments\n",
    "# These are needed to initialize the model\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        # Match the default arguments from main.py\n",
    "        self.loss = 'weighted_CCE'\n",
    "        self.track = 'DF'\n",
    "        self.seed = 1234\n",
    "        self.cudnn_deterministic_toggle = True\n",
    "        self.cudnn_benchmark_toggle = False\n",
    "        self.algo = 0  # No Rawboost augmentation for inference\n",
    "        \n",
    "        # Parameters for different augmentation algorithms (not used in inference)\n",
    "        self.nBands = 5\n",
    "        self.minF = 20\n",
    "        self.maxF = 8000\n",
    "        self.minBW = 100\n",
    "        self.maxBW = 1000\n",
    "        self.minCoeff = 10\n",
    "        self.maxCoeff = 100\n",
    "        self.minG = 0\n",
    "        self.maxG = 0\n",
    "        self.minBiasLinNonLin = 5\n",
    "        self.maxBiasLinNonLin = 20\n",
    "        self.N_f = 5\n",
    "        self.P = 10\n",
    "        self.g_sd = 2\n",
    "        self.SNRmin = 10\n",
    "        self.SNRmax = 40\n",
    "\n",
    "# Create dummy args\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess audio files using a similar approach to the original code\n",
    "def preprocess_audio(audio_path, sr=16000):\n",
    "    \"\"\"\n",
    "    Load and preprocess audio file for the SLS model based on original repository's approach\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use librosa to load the audio file\n",
    "        audio, sample_rate = librosa.load(audio_path, sr=sr, mono=True)\n",
    "        \n",
    "        # Normalize audio to match the preprocessing in the original code\n",
    "        audio = librosa.util.normalize(audio)\n",
    "        \n",
    "        # Handle length - original repo expects 64600 samples (approx 4 seconds at 16kHz)\n",
    "        target_len = 64600\n",
    "        if len(audio) < target_len:\n",
    "            # Pad if shorter\n",
    "            audio = np.pad(audio, (0, target_len - len(audio)))\n",
    "        elif len(audio) > target_len:\n",
    "            # Take the first part if longer\n",
    "            audio = audio[:target_len]\n",
    "            \n",
    "        return audio\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {audio_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model following the approach in main.py\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create model instance using the same approach as in main.py\n",
    "model = Model(args, device)\n",
    "\n",
    "# Count parameters (optional)\n",
    "nb_params = sum([param.view(-1).size()[0] for param in model.parameters()])\n",
    "print(f\"Model has {nb_params:,} parameters\")\n",
    "\n",
    "# Wrap with DataParallel as in original code\n",
    "model = nn.DataParallel(model).to(device)\n",
    "\n",
    "# Load pretrained model weights (adjust path if needed)\n",
    "model_path = \"pretrained_models/asvdf_sls_best.pth\"\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "print(\"SLS model loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "\n",
    "class AudioDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, file_list, sample_rate=16000):\n",
    "        self.file_list = file_list\n",
    "        self.sample_rate = sample_rate\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_list[idx]\n",
    "        features = preprocess_audio(file_path, sr=self.sample_rate)\n",
    "        if features is None:\n",
    "            # Return zeros if extraction failed\n",
    "            features = np.zeros(64600)  # Match expected length from original code\n",
    "        \n",
    "        # Convert to tensor\n",
    "        features_tensor = torch.FloatTensor(features)\n",
    "        return features_tensor, file_path\n",
    "\n",
    "# Create dataset and dataloader\n",
    "batch_size = 16\n",
    "num_workers = 4\n",
    "pickle_file = 'sls_scores.pkl'\n",
    "force_overwrite = False  # Set to True to force recalculation\n",
    "\n",
    "if os.path.exists(pickle_file) and not force_overwrite:\n",
    "    with open(pickle_file, 'rb') as f:\n",
    "        all_scores = pickle.load(f)\n",
    "    print(\"Loaded scores from pickle file. Skipping inference.\")\n",
    "else:\n",
    "    all_scores = {}\n",
    "    \n",
    "    # Create dataset and dataloader\n",
    "    dataset = AudioDataset(file_paths)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                            shuffle=False, num_workers=num_workers)\n",
    "    \n",
    "    # Run inference on batches\n",
    "    for batch_features, batch_paths in tqdm(dataloader, desc=\"Processing batches\"):\n",
    "        batch_features = batch_features.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Get model outputs - follow the scoring approach in produce_evaluation_file\n",
    "            batch_out = model(batch_features)\n",
    "            # Extract scores (matching the original code in produce_evaluation_file)\n",
    "            batch_score = batch_out[:, 1].cpu().numpy()\n",
    "        \n",
    "        # Store scores by filepath\n",
    "        for file_path, score in zip(batch_paths, batch_score):\n",
    "            all_scores[file_path] = float(score)\n",
    "        \n",
    "        # Save progress after each batch\n",
    "        with open(pickle_file, 'wb') as f:\n",
    "            pickle.dump(all_scores, f)\n",
    "            \n",
    "    print(f\"Processed {len(all_scores)} files. Results saved to {pickle_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize score distribution\n",
    "scores = list(all_scores.values())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "n, bins, patches = plt.hist(scores, bins=50, alpha=0.7, \n",
    "                           color='green', edgecolor='black')\n",
    "\n",
    "# Set threshold based on EER from paper\n",
    "# According to the repository, higher scores indicate deepfake/spoof\n",
    "eer_threshold = 0.5  # Default threshold for SLS model\n",
    "\n",
    "# Add vertical line for threshold\n",
    "plt.axvline(eer_threshold, color='red', linestyle='--',\n",
    "           linewidth=2, label=f'EER Threshold: {eer_threshold:.4f}')\n",
    "\n",
    "plt.title('DF Detection Scores - SLSforASVspoof', fontsize=14)\n",
    "plt.xlabel('Score Value (higher = more likely fake)', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add text annotations\n",
    "plt.text(0.05, 0.95, f'Total files: {len(scores)}', \n",
    "        transform=plt.gca().transAxes, verticalalignment='top')\n",
    "plt.text(0.05, 0.90, f'Mean score: {np.mean(scores):.4f}',\n",
    "        transform=plt.gca().transAxes, verticalalignment='top')\n",
    "plt.text(0.05, 0.85, f'Files with score > threshold: {sum(s > eer_threshold for s in scores)}',\n",
    "        transform=plt.gca().transAxes, verticalalignment='top')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Save results to a CSV file for further analysis\n",
    "results_df = pd.DataFrame({\n",
    "    'file_path': list(all_scores.keys()),\n",
    "    'score': list(all_scores.values()),\n",
    "    'prediction': ['spoof' if s > eer_threshold else 'bonafide' for s in all_scores.values()]\n",
    "})\n",
    "\n",
    "# Display the first few results\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLSforASVspoof Deepfake Detection Notebook\n",
    "\n",
    "This notebook demonstrates how to use the SLS (Supervised Label Smoothing) model for detecting deepfake audio samples.\n",
    "\n",
    "**Steps:**\n",
    "1. Import dependencies and define utility functions\n",
    "2. Load audio files from a directory\n",
    "3. Define preprocessing functions for audio data\n",
    "4. Load the pretrained SLS model\n",
    "5. Run batch inference on audio files\n",
    "6. Visualize detection scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_audio_files_recursive(folder_path, formats=('wav', 'flac'), exclude_prefix=('.', '__')):\n",
    "    \"\"\"\n",
    "    Recursively find audio files in a directory with specified extensions.\n",
    "    \n",
    "    Args:\n",
    "        folder_path (str): Root directory to search.\n",
    "        formats (tuple): File extensions to include (lowercase).\n",
    "        exclude_prefix (tuple): Skip directories starting with these prefixes.\n",
    "    \n",
    "    Returns:\n",
    "        list: Full paths to audio files.\n",
    "    \"\"\"\n",
    "    valid_files = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        # Skip hidden or special directories\n",
    "        dirs[:] = [d for d in dirs if not d.startswith(exclude_prefix)]\n",
    "        for file in files:\n",
    "            ext = os.path.splitext(file)[1][1:].lower()  # Extension without the dot\n",
    "            if ext in formats:\n",
    "                full_path = os.path.join(root, file)\n",
    "                valid_files.append(full_path)\n",
    "    return valid_files\n",
    "\n",
    "# Set path to your audio files directory\n",
    "input_folder = '/data/audio_files'\n",
    "file_paths = get_audio_files_recursive(input_folder, formats=('wav', 'flac'))\n",
    "print(f\"Found {len(file_paths)} audio files ({', '.join(set([os.path.splitext(f)[1] for f in file_paths]))} formats)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model architecture\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "from models.SLS_RawNet2 import MainModel\n",
    "\n",
    "# Function to extract features from audio\n",
    "def extract_features(audio_path, sr=16000):\n",
    "    \"\"\"Load and preprocess audio file for SLS model\"\"\"\n",
    "    # Load audio with librosa\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(audio_path, sr=sr, mono=True)\n",
    "        \n",
    "        # Check audio length and pad/trim if necessary\n",
    "        target_len = sr * 4  # 4 seconds\n",
    "        if len(audio) < target_len:\n",
    "            # Pad audio if shorter than target length\n",
    "            audio = np.pad(audio, (0, target_len - len(audio)))\n",
    "        elif len(audio) > target_len:\n",
    "            # Take the first 4 seconds if longer\n",
    "            audio = audio[:target_len]\n",
    "            \n",
    "        return audio\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {audio_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create the SLS model instance\n",
    "model = MainModel()\n",
    "\n",
    "# Load pretrained model weights\n",
    "model_path = \"pretrained_models/asvdf_sls_best.pth\"\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"SLS model loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "\n",
    "class AudioDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, file_list, sample_rate=16000):\n",
    "        self.file_list = file_list\n",
    "        self.sample_rate = sample_rate\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_list[idx]\n",
    "        features = extract_features(file_path, sr=self.sample_rate)\n",
    "        if features is None:\n",
    "            # Return zeros if extraction failed\n",
    "            features = np.zeros(self.sample_rate * 4)\n",
    "        \n",
    "        # Convert to tensor\n",
    "        features_tensor = torch.FloatTensor(features)\n",
    "        return features_tensor, file_path\n",
    "\n",
    "# Create dataset and dataloader\n",
    "batch_size = 16\n",
    "num_workers = 4\n",
    "pickle_file = 'sls_scores.pkl'\n",
    "force_overwrite = False  # Set to True to force recalculation\n",
    "\n",
    "if os.path.exists(pickle_file) and not force_overwrite:\n",
    "    with open(pickle_file, 'rb') as f:\n",
    "        all_scores = pickle.load(f)\n",
    "    print(\"Loaded scores from pickle file. Skipping inference.\")\n",
    "else:\n",
    "    all_scores = {}\n",
    "    \n",
    "    # Create dataset and dataloader\n",
    "    dataset = AudioDataset(file_paths)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                            shuffle=False, num_workers=num_workers)\n",
    "    \n",
    "    # Run inference on batches\n",
    "    for batch_features, batch_paths in tqdm(dataloader, desc=\"Processing batches\"):\n",
    "        batch_features = batch_features.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Get model outputs\n",
    "            outputs = model(batch_features)\n",
    "            # Extract scores (assuming binary classification with bonafide=0, spoof=1)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            scores = probs[:, 1].cpu().numpy()  # Probability of being spoof/fake\n",
    "        \n",
    "        # Store scores by filepath\n",
    "        for file_path, score in zip(batch_paths, scores):\n",
    "            all_scores[file_path] = float(score)\n",
    "        \n",
    "        # Save progress after each batch\n",
    "        with open(pickle_file, 'wb') as f:\n",
    "            pickle.dump(all_scores, f)\n",
    "            \n",
    "    print(f\"Processed {len(all_scores)} files. Results saved to {pickle_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize score distribution\n",
    "scores = list(all_scores.values())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "n, bins, patches = plt.hist(scores, bins=50, alpha=0.7, \n",
    "                           color='green', edgecolor='black')\n",
    "\n",
    "# SLS model threshold (according to paper)\n",
    "eer_threshold = 0.5  # Default threshold for SLS model\n",
    "\n",
    "# Add vertical line for threshold\n",
    "plt.axvline(eer_threshold, color='red', linestyle='--',\n",
    "           linewidth=2, label=f'EER Threshold: {eer_threshold:.4f}')\n",
    "\n",
    "plt.title('DF Detection Scores - SLSforASVspoof', fontsize=14)\n",
    "plt.xlabel('Score Value (higher = more likely fake)', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add text annotations\n",
    "plt.text(0.05, 0.95, f'Total files: {len(scores)}', \n",
    "        transform=plt.gca().transAxes, verticalalignment='top')\n",
    "plt.text(0.05, 0.90, f'Mean score: {np.mean(scores):.4f}',\n",
    "        transform=plt.gca().transAxes, verticalalignment='top')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

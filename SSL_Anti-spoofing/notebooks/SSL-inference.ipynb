{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39507a4f",
   "metadata": {},
   "source": [
    "# ASVspoof DF Evaluation Notebook\n",
    "\n",
    "This notebook performs inference on your own list of WAV files using a pretrained DF detection model.  \n",
    "The file `yourtts_wav_files.txt` contains the full paths to your audio files.  \n",
    "We import the model and necessary functions from the original repository without modifying any files.\n",
    "\n",
    "**Steps:**\n",
    "1. Import dependencies and define utility functions.\n",
    "2. Define a custom dataset to load your WAV files.\n",
    "3. Load your file list.\n",
    "4. Create a DataLoader.\n",
    "5. Load the pretrained model and set it to evaluation mode.\n",
    "6. Run inference and collect scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5011d6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional Cell: Generate WAV file list from directory\n",
    "import os\n",
    "\n",
    "def get_audio_files_recursive(folder_path, formats=('wav', 'flac'), exclude_prefix=('.', '__')):\n",
    "    \"\"\"\n",
    "    Recursively find audio files in a directory with specified extensions.\n",
    "    \n",
    "    Args:\n",
    "        folder_path (str): Root directory to search\n",
    "        formats (tuple): File extensions to include (lowercase)\n",
    "        exclude_prefix (tuple): Skip directories starting with these prefixes\n",
    "    \n",
    "    Returns:\n",
    "        list: Full paths to audio files\n",
    "    \"\"\"\n",
    "    valid_files = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        # Skip hidden/special directories\n",
    "        dirs[:] = [d for d in dirs if not d.startswith(exclude_prefix)]\n",
    "        \n",
    "        for file in files:\n",
    "            # Extract extension and check against allowed formats\n",
    "            ext = os.path.splitext(file)[1][1:].lower()  # Get extension without dot\n",
    "            if ext in formats:\n",
    "                full_path = os.path.join(root, file)\n",
    "                valid_files.append(full_path)\n",
    "                \n",
    "    return valid_files\n",
    "\n",
    "input_folder = '/root/rafaello/datasets/BRSpeech_CML_TTS_v04012024/'\n",
    "#input_folder = '/root/rafaello/datasets/test/'\n",
    "file_paths = get_audio_files_recursive(input_folder, formats=('wav', 'flac'))\n",
    "print(f\"Found {len(file_paths)} audio files ({', '.join(set([os.path.splitext(f)[1] for f in file_paths]))} formats)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4de9205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Imports and utility functions\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Utility function to pad or truncate an audio signal to a fixed length.\n",
    "def pad(x, desired_length):\n",
    "    if len(x) >= desired_length:\n",
    "        return x[:desired_length]\n",
    "    else:\n",
    "        pad_width = desired_length - len(x)\n",
    "        return np.pad(x, (0, pad_width), mode='constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d06fa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Define a custom dataset to load WAV files\n",
    "\n",
    "class CustomWavDataset(Dataset):\n",
    "    def __init__(self, file_list, sr=16000, cut=64600):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            file_list (list): List of full paths to WAV files.\n",
    "            sr (int): Target sampling rate.\n",
    "            cut (int): Fixed length (in samples) for each audio waveform.\n",
    "        \"\"\"\n",
    "        self.file_list = file_list\n",
    "        self.sr = sr\n",
    "        self.cut = cut\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_list[idx]\n",
    "        # Load the audio file; force sample rate to 16 kHz.\n",
    "        signal, _ = librosa.load(file_path, sr=self.sr)\n",
    "        signal_padded = pad(signal, self.cut)\n",
    "        # Convert signal to a PyTorch tensor.\n",
    "        signal_tensor = torch.tensor(signal_padded, dtype=torch.float32)\n",
    "        # Use the filename as a unique identifier.\n",
    "        utt_id = os.path.basename(file_path)\n",
    "        return signal_tensor, utt_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4efaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Skip if using Cell 1\n",
    "# If Cell 1 was run, do not override file_paths\n",
    "if \"file_paths\" not in globals():\n",
    "    file_list_path = \"/root/rafaello/datasets/yourtts_wav_files.txt\"  # Update path if needed.\n",
    "    with open(file_list_path, \"r\") as f:\n",
    "        file_paths = [line.strip() for line in f if line.strip()]\n",
    "    print(f\"Loaded {len(file_paths)} wav file paths.\")\n",
    "else:\n",
    "    print(f\"Using dynamically detected {len(file_paths)} audio files from Cell 1.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b5a9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Create the dataset and dataloader\n",
    "\n",
    "dataset = CustomWavDataset(file_paths)\n",
    "# Adjust the batch size as needed.\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee89ca88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from argparse import Namespace\n",
    "\n",
    "# Set CUDA_VISIBLE_DEVICES first\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create minimal args with required parameters\n",
    "args = Namespace(\n",
    "    track='DF',\n",
    "    model_path='./Best_LA_model_for_DF.pth',\n",
    "    protocols_path='./protocols/',\n",
    "    database_path='./database/',\n",
    "    loss='WCE'\n",
    ")\n",
    "\n",
    "# Initialize model same way as main_SSL_DF.py (lines 238-240)\n",
    "from model import Model\n",
    "model = Model(args, device)\n",
    "model = torch.nn.DataParallel(model).to(device)  # Critical for weight loading\n",
    "\n",
    "# Load weights using same method as line 247\n",
    "checkpoint = torch.load(args.model_path, map_location=device)\n",
    "model.load_state_dict(checkpoint, strict=False)  # Allow partial loading\n",
    "\n",
    "model.eval()\n",
    "print(\"Model loaded in evaluation mode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1900bf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Run inference with continuous save\n",
    "from tqdm.autonotebook import tqdm\n",
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "# Configuration\n",
    "load_scores_file = \"./outputs/df_detection_scores.pkl\"  # File to load existing scores\n",
    "save_scores_file = \"./outputs/df_detection_scores.pkl\"  # File to save scores\n",
    "force_recalculate = False        # Set to True to ignore saved scores and recompute\n",
    "\n",
    "# If not forcing recalculation and scores exist, load and skip inference\n",
    "if not force_recalculate and os.path.exists(load_scores_file):\n",
    "    print(f\"Loading existing scores from {load_scores_file}...\")\n",
    "    with open(load_scores_file, \"rb\") as f:\n",
    "        all_scores = pickle.load(f)\n",
    "    print(\"Scores loaded. Skipping inference.\")\n",
    "else:\n",
    "    print(\"No saved scores found or recalculation forced. Running inference...\")\n",
    "    all_scores = {}  # Initialize an empty dictionary\n",
    "\n",
    "    # Identify unprocessed files\n",
    "    all_utt_ids = set(file_paths)  # Assuming `file_paths` contains all expected files\n",
    "    processed_utt_ids = set(all_scores.keys())\n",
    "\n",
    "    # If all files are already processed, skip inference\n",
    "    if processed_utt_ids >= all_utt_ids:\n",
    "        print(f\"All {len(all_utt_ids)} files are already processed. Skipping inference.\")\n",
    "    else:\n",
    "        print(f\"Processing {len(all_utt_ids - processed_utt_ids)} new files...\")\n",
    "\n",
    "        # Track progress and save results\n",
    "        with torch.no_grad():\n",
    "            for batch_x, utt_ids in tqdm(dataloader, \n",
    "                                         desc=\"Processing batches\", \n",
    "                                         unit=\"batch\",\n",
    "                                         dynamic_ncols=True):\n",
    "                # Skip already processed files\n",
    "                utt_ids_to_process = [uid for uid in utt_ids if uid not in all_scores]\n",
    "                if not utt_ids_to_process:\n",
    "                    continue\n",
    "\n",
    "                # Process the batch\n",
    "                batch_x = batch_x.to(device)\n",
    "                batch_out = model(batch_x)\n",
    "                batch_scores = batch_out[:, 1].cpu().numpy()\n",
    "\n",
    "                # Update scores dictionary and save immediately\n",
    "                for utt_id, score in zip(utt_ids, batch_scores):\n",
    "                    all_scores[utt_id] = score\n",
    "\n",
    "                # Save scores after each batch\n",
    "                with open(save_scores_file, \"wb\") as f:\n",
    "                    pickle.dump(all_scores, f)\n",
    "\n",
    "        print(f\"\\nInference complete. Processed {len(all_scores)} files.\")\n",
    "        print(f\"Scores saved to: {save_scores_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc28c282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Visualize score distribution with threshold\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np  # Required for np.mean\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Ensure scores are loaded\n",
    "if not 'all_scores' in globals():\n",
    "    if os.path.exists(scores_file):\n",
    "        print(f\"Loading scores from {scores_file}...\")\n",
    "        with open(scores_file, \"rb\") as f:\n",
    "            all_scores = pickle.load(f)\n",
    "    else:\n",
    "        raise RuntimeError(\"Scores file not found, and inference was not run.\")\n",
    "\n",
    "# Convert scores to a list\n",
    "scores = list(all_scores.values())\n",
    "\n",
    "# Create histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "n, bins, patches = plt.hist(scores, bins=100, alpha=0.7, \n",
    "                            color='blue', edgecolor='black')\n",
    "\n",
    "# Add threshold line\n",
    "threshold = -3.5324\n",
    "plt.axvline(threshold, color='red', linestyle='--', \n",
    "           linewidth=2, label=f'Threshold: {threshold:.4f}')\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('DF Detection Scores - F5-TTS on SSL-Anti-Spoofing', fontsize=14)\n",
    "plt.xlabel('Score Value', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add count annotations\n",
    "plt.text(0.05, 0.95, f'Total files: {len(scores)}', \n",
    "         transform=plt.gca().transAxes, verticalalignment='top')\n",
    "plt.text(0.05, 0.90, f'Mean score: {np.mean(scores):.4f}', \n",
    "         transform=plt.gca().transAxes, verticalalignment='top')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
